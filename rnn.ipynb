{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "from os import listdir\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from random import randint\n",
    "import data\n",
    "from tqdm import tnrange, tqdm_notebook, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.', 'and', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', '.', 'and', 'the', 'spirit', 'of', 'god', 'moved', 'upon', 'the', 'face']\n",
      "1909\n",
      "29602\n",
      "[5, 1, 3, 45, 24, 451, 1816, 2, 1, 1698]\n",
      "[1, 3, 45, 24, 451, 1816, 2, 1, 1698, 9]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1900\n",
    "d, id_to_token = data.get_data(vocab_size)\n",
    "for k in id_to_token:\n",
    "    if id_to_token[k] == 'eos':\n",
    "        id_to_token[k] = '\\n'\n",
    "print(len(d))\n",
    "x, y = d[10:20], d[11:21]\n",
    "print([np.argmax(j) for j in x])\n",
    "print([np.argmax(j) for j in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "input_size = output_size = vocab_size\n",
    "hidden_layer = 300\n",
    "inp_out_size = vocab_size\n",
    "learning_rate = 0.1\n",
    "num_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "initializer = tf.random_normal_initializer(mean=0, stddev=0.001, dtype=tf.float32)\n",
    "Wxh = tf.get_variable('Wxh', shape=[input_size, hidden_layer], initializer=initializer)\n",
    "Whh = tf.get_variable('Whh', shape=[hidden_layer, hidden_layer], initializer=initializer)\n",
    "Why = tf.get_variable('Why',shape=[hidden_layer, output_size], initializer=initializer)\n",
    "by = tf.get_variable('by', shape=[output_size], initializer=initializer)\n",
    "# weights associated with update gate\n",
    "Wxz = tf.get_variable('Wxz', shape=[input_size, hidden_layer], initializer=initializer)\n",
    "Whz = tf.get_variable('Whz', shape=[hidden_layer, hidden_layer], initializer=initializer)\n",
    "# weights associated with the reset gate\n",
    "Wxr = tf.get_variable('Wxr', shape=[input_size, hidden_layer], initializer=initializer)\n",
    "Whr = tf.get_variable('Whr', shape=[hidden_layer, hidden_layer], initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recurrence(prev, inp):\n",
    "    i = tf.reshape(inp, shape=[1, -1])\n",
    "    p = tf.reshape(prev, shape=[1, -1])\n",
    "    z = tf.nn.sigmoid(tf.matmul(i, Wxz) + tf.matmul(p, Whz))    # update gate\n",
    "    r = tf.nn.sigmoid(tf.matmul(i, Wxr) + tf.matmul(p, Whr))    # reset gate\n",
    "    h_ = tf.nn.tanh(tf.matmul(i, Wxh) + tf.matmul(tf.mul(p, r), Whh))\n",
    "    h = tf.nn.tanh(tf.mul(tf.sub(tf.ones_like(z), z), h_) + tf.mul(z, p))\n",
    "    return tf.reshape(h, [hidden_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(shape=[None, inp_out_size], dtype=tf.float32)\n",
    "b = tf.placeholder(shape=[None, inp_out_size], dtype=tf.float32)\n",
    "initial = tf.placeholder(shape=[hidden_layer], dtype=tf.float32)\n",
    "states = tf.nn.dropout(tf.scan(recurrence, a, initializer=initial), keep_prob=0.8)\n",
    "outputs = tf.nn.softmax(tf.matmul(states, Why) + by)\n",
    "loss = -tf.reduce_sum(b*tf.log(outputs))\n",
    "# loss = tf.sqrt(tf.reduce_sum(tf.square(tf.sub(outputs, b))))\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
    "\n",
    "# clipping gradients between -1 and 1.\n",
    "grad_var_pairs = optimizer.compute_gradients(loss, tf.trainable_variables())\n",
    "clipped_grad_var_pairs = [(tf.clip_by_value(gv[0], -4, 4), gv[1]) for gv in grad_var_pairs]\n",
    "optimize_op = optimizer.apply_gradients(clipped_grad_var_pairs)\n",
    "\n",
    "# optimize_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(sess, n):\n",
    "    x, _ = data.sample(d, 1)\n",
    "    gen = [id_to_token[np.argmax(x[0])]]\n",
    "    h = np.zeros(hidden_layer)\n",
    "    for i in range(n):\n",
    "        o, h = sess.run([outputs, states], {a:x, initial: h})\n",
    "        h = h.reshape(hidden_layer)\n",
    "        o = np.argmax(o[0])\n",
    "        gen.append(id_to_token[o])\n",
    "        x = [0] * inp_out_size\n",
    "        x[o] = 1\n",
    "#         print np.argmax(x)\n",
    "        x = [x]\n",
    "    print(' '.join(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if already trained previously, just restore\n",
    "to_restore = False\n",
    "\n",
    "if to_restore:\n",
    "    saver.restore(sess, 'model.ckpt')\n",
    "else:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4000 [00:00<?, ?it/s]\u001b[A\n",
      "loss 64:   8%|â–Š         | 300/4000 [00:45<09:24,  6.55it/s]"
     ]
    }
   ],
   "source": [
    "iterations = 4000\n",
    "h = np.zeros(hidden_layer)\n",
    "t = trange(iterations, miniters=100)\n",
    "for i in t:\n",
    "#     x, y = data.sample(d, num_steps)\n",
    "    if ix + num_steps >= len(d):\n",
    "        ix = 0\n",
    "#         t.set_description('one epoch complete')\n",
    "    h = np.zeros(hidden_layer)\n",
    "    x, y = d[ix : ix + num_steps], d[ix + 1 : ix + num_steps + 1]   \n",
    "    l, o, _ = sess.run([loss, outputs, optimize_op], {a: x, b: y, initial: h})\n",
    "#     if i % 50 == 0:\n",
    "    t.set_description('loss %i' %l)\n",
    "#         generate(sess, 50)\n",
    "    ix += num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving model\n",
    "# saver.save(sess, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "much traction which itself required marketing dollars.we were stuck in a vicious loop , to be able to pursue his robotics and robotics passion before that time and that should be part of your product market fit , an industry has , by a month ago , this is an one of the human computer interaction ) . image is very a time . we have a great set to new yourself focused and technology innovation . in the very half of our product or on . and robotics and we could do any path we wanted to and that helped\n"
     ]
    }
   ],
   "source": [
    "generate(sess, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess.run(Whh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "003619ed021f4db28c5a928e27176b5b": {
     "views": []
    },
    "036f3145bc9047e7aa61c83af5e8d324": {
     "views": []
    },
    "0b116bf2b81c49f1898656284b6d6c53": {
     "views": []
    },
    "138722c9ae6344f5a7e10981f3d90085": {
     "views": []
    },
    "145e9efe5060475fbe827cb8c97c0650": {
     "views": []
    },
    "1cd9aec540c645e78c9b9a28d51d36c6": {
     "views": []
    },
    "1f8bacacd5074538b701e0d57edae47a": {
     "views": []
    },
    "275e5c189e2d469b9eb068411f5f1ddb": {
     "views": []
    },
    "317996c350944c21a8efcdf4ec2f48ec": {
     "views": []
    },
    "3728a7b92c534db28b71cc6980357666": {
     "views": []
    },
    "37a452b6c763431385eb8331551a15a2": {
     "views": []
    },
    "397d6040ab5543189973f1dab3080bb9": {
     "views": []
    },
    "3db33239d0ae4d9680b94b56453f6ef5": {
     "views": []
    },
    "4065c340af8a464da8b72492c2333307": {
     "views": []
    },
    "4212e30276914ea0b95729484b1310bb": {
     "views": []
    },
    "4406b5e18a2e445a8ee8a81da61e0c97": {
     "views": []
    },
    "4fa053e3558b4333b52b4bf21ad5c6a5": {
     "views": []
    },
    "54af1f27159c4ce985bf6d021f60bc48": {
     "views": []
    },
    "5bdffbee32554f07b67438c1258793f9": {
     "views": []
    },
    "5e62839d358a4104916c924a3dd8a76b": {
     "views": []
    },
    "5f0408804e7046f38ce40f1f232f6a37": {
     "views": []
    },
    "60ebb9ee534548d8af71ec7eb7436dc8": {
     "views": []
    },
    "61b231566266410ab86b48be48573d77": {
     "views": []
    },
    "82d43aa61d544645b17884f92ae95c67": {
     "views": []
    },
    "8500e3764f324ba4b205a6fe4e81e270": {
     "views": []
    },
    "87dbb1dba0884be6abe7257ec89c6db9": {
     "views": []
    },
    "92e865db5f2944f784a201f021672216": {
     "views": []
    },
    "9adb195f33734d26a37784f7b72463d5": {
     "views": []
    },
    "9cad9880ad29482cbf245edfc0f0b96d": {
     "views": []
    },
    "9ce2ceedab914e958831c35869b7dee1": {
     "views": []
    },
    "9e116951526b44deb06bc30045df60d4": {
     "views": []
    },
    "a198693f98e14ff191a20b119b3c43c7": {
     "views": []
    },
    "a1b0b32040d447f2b186bfaedb454d11": {
     "views": []
    },
    "a3e096d994674a64ab438337d5ca53f6": {
     "views": []
    },
    "a57faf3583e04949ac7dbe6d91f82ce2": {
     "views": []
    },
    "a898969ef4bf42659aa24f5cfa153cad": {
     "views": []
    },
    "abf74e7ff5394ec2ab5a7068a991d25e": {
     "views": []
    },
    "adf0c374ded24b64b2c265d9d9fa0a67": {
     "views": []
    },
    "aee19342389c49e1b1c1943f2df15e37": {
     "views": []
    },
    "c0785db50b7545e08f461daf9cc02a3f": {
     "views": []
    },
    "c570f6d6605d438f8394274ad3045ec2": {
     "views": []
    },
    "d1aab9ea81614f6ebfd7b9aec8ffb6a9": {
     "views": []
    },
    "d37941fac9404f9fb11a26a23592f830": {
     "views": []
    },
    "d67f638ee1484bdeb6f86a94b5b17966": {
     "views": []
    },
    "e107e47822bd4915ab2fba995a28b798": {
     "views": []
    },
    "e677c5d1bc4644718e7dc3ccbc69f3e4": {
     "views": []
    },
    "f31f04bfcb2243a580d3aa7e8b80a152": {
     "views": []
    },
    "faf81fb201c74cd68143bd03caa05d49": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
