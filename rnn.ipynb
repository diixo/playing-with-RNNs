{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\n', u'!', u' ', u\"'\", u')', u'(', u',', u'.', u';', u':', u'?', u'a', u'c', u'b', u'e', u'd', u'g', u'f', u'i', u'h', u'k', u'j', u'm', u'l', u'o', u'n', u'p', u's', u'r', u'u', u't', u'w', u'y', u'z', u'a', u'c', u'b', u'e', u'd', u'g', u'f', u'i', u'h', u'k', u'j', u'm', u'l', u'o', u'n', u'q', u'p', u's', u'r', u'u', u't', u'w', u'v', u'y', u'x', u'z']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "from os import listdir\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from random import randint\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'we', u'have', u'waited', u'for', u'this', u'moment', u'for', u'a', u'long', u'time', u'.', u'as', u'a', u'small', u'startup', u'with', u'resource', u'constraints', u'but', u'ambitious', u'goals', u'to', u'reach', u'the', u'pinnacle', u'of', u'what\\u2019s', u'possible', u'in', u'artificial', u'intelligence', u'research', u',', u'we', u'think', u'we', u'have', u'come', u'a', u'long']\n",
      "1651\n",
      "8393\n",
      "[1, 16, 5, 261, 62, 12, 1046, 1478, 43, 248]\n",
      "[16, 5, 261, 62, 12, 1046, 1478, 43, 248, 1632]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1651\n",
    "d, id_to_token = data.get_data(vocab_size)\n",
    "for k in id_to_token:\n",
    "    if id_to_token[k] == 'eos':\n",
    "        id_to_token[k] = '\\n'\n",
    "print len(d)\n",
    "x, y = d[10:20], d[11:21]\n",
    "print [np.argmax(j) for j in x]\n",
    "print [np.argmax(j) for j in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "input_size = output_size = vocab_size\n",
    "hidden_layer = 300\n",
    "inp_out_size = vocab_size\n",
    "learning_rate = 0.1\n",
    "num_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "initializer = tf.random_normal_initializer(mean=0, stddev=0.001, dtype=tf.float32)\n",
    "Wxh = tf.get_variable('Wxh', shape=[input_size, hidden_layer], initializer=initializer)\n",
    "Whh = tf.get_variable('Whh', shape=[hidden_layer, hidden_layer], initializer=initializer)\n",
    "Why = tf.get_variable('Why',shape=[hidden_layer, output_size], initializer=initializer)\n",
    "by = tf.get_variable('by', shape=[output_size], initializer=initializer)\n",
    "# weights associated with update gate\n",
    "Wxz = tf.get_variable('Wxz', shape=[input_size, hidden_layer], initializer=initializer)\n",
    "Whz = tf.get_variable('Whz', shape=[hidden_layer, hidden_layer], initializer=initializer)\n",
    "# weights associated with the reset gate\n",
    "Wxr = tf.get_variable('Wxr', shape=[input_size, hidden_layer], initializer=initializer)\n",
    "Whr = tf.get_variable('Whr', shape=[hidden_layer, hidden_layer], initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recurrence(prev, inp):\n",
    "    i = tf.reshape(inp, shape=[1, -1])\n",
    "    p = tf.reshape(prev, shape=[1, -1])\n",
    "    z = tf.nn.sigmoid(tf.matmul(i, Wxz) + tf.matmul(p, Whz))    # update gate\n",
    "    r = tf.nn.sigmoid(tf.matmul(i, Wxr) + tf.matmul(p, Whr))    # reset gate\n",
    "    h_ = tf.nn.tanh(tf.matmul(i, Wxh) + tf.matmul(tf.mul(p, r), Whh))\n",
    "    h = tf.nn.tanh(tf.mul(tf.sub(tf.ones_like(z), z), h_) + tf.mul(z, p))\n",
    "    return tf.reshape(h, [hidden_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(shape=[None, inp_out_size], dtype=tf.float32)\n",
    "b = tf.placeholder(shape=[None, inp_out_size], dtype=tf.float32)\n",
    "initial = tf.placeholder(shape=[hidden_layer], dtype=tf.float32)\n",
    "states = tf.nn.dropout(tf.scan(recurrence, a, initializer=initial), keep_prob=0.8)\n",
    "outputs = tf.nn.softmax(tf.matmul(states, Why) + by)\n",
    "loss = -tf.reduce_sum(b*tf.log(outputs))\n",
    "# loss = tf.sqrt(tf.reduce_sum(tf.square(tf.sub(outputs, b))))\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
    "\n",
    "# clipping gradients between -1 and 1.\n",
    "grad_var_pairs = optimizer.compute_gradients(loss, tf.trainable_variables())\n",
    "clipped_grad_var_pairs = [(tf.clip_by_value(gv[0], -4, 4), gv[1]) for gv in grad_var_pairs]\n",
    "optimize_op = optimizer.apply_gradients(clipped_grad_var_pairs)\n",
    "\n",
    "# optimize_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(sess, n):\n",
    "    x, _ = data.sample(d, 1)\n",
    "    gen = [id_to_token[np.argmax(x[0])]]\n",
    "    h = np.zeros(hidden_layer)\n",
    "    for i in range(n):\n",
    "        o, h = sess.run([outputs, states], {a:x, initial: h})\n",
    "        h = h.reshape(hidden_layer)\n",
    "        o = np.argmax(o[0])\n",
    "        gen.append(id_to_token[o])\n",
    "        x = [0] * inp_out_size\n",
    "        x[o] = 1\n",
    "#         print np.argmax(x)\n",
    "        x = [x]\n",
    "    print ' '.join(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if already trained previously, just restore\n",
    "to_restore = False\n",
    "\n",
    "if to_restore:\n",
    "    saver.restore(sess, 'model.ckpt')\n",
    "else:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss = 146.211547852\n",
      "on a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n",
      "one epoch complete\n",
      "iteration 500, loss = 117.030181885\n",
      "my turing . we have a lot of our of our . we have have to have a lot of the system of the time . we have to build a lot of our . we have a lot of our of our . we have a lot of our .\n",
      "one epoch complete\n",
      "iteration 1000, loss = 73.7587127686\n",
      "product . we have it to build the market . we are a lot to build a year . with technology and robotics . we have it was a great time . we are going to build a year . we are going to be our products and robotics . we\n",
      "one epoch complete\n",
      "iteration 1500, loss = 83.6778793335\n",
      "this is a lot of the world is that we are no longer no longer way to build product and become the market . we are no longer to product and it has become a lot of the new market . and we are no longer no longer system to build\n",
      "one epoch complete\n",
      "iteration 2000, loss = 55.8870697021\n",
      "us . he was pretty in in terms of machine and computer vision and become the market . i wanted to get to do and i could be able to great team for the first time . he was very likely the last 4 years this is that i was waiting\n",
      "one epoch complete\n",
      "iteration 2500, loss = 51.7379226685\n",
      ". we are good good business use cases , most of the team was the quintessential for this problem . we were trying to solve , as as possible , relentlessly one data difficult for some of the business use cases , our product and believe in your vision . one\n",
      "one epoch complete\n",
      "one epoch complete\n",
      "iteration 3000, loss = 30.573513031\n",
      "self-sustainable in a few very a human or a facebook ai research . we have been working in various image recognition problems for a . this last summer system called up the problem was only given a human computer vision for this kind of visual description task could be used to\n",
      "one epoch complete\n",
      "iteration 3500, loss = 14.7380466461\n",
      "time . we have rebranded as artifacia after our research focused and thought it approach leads ahead same time . we didn’t have the right resources at things where i started across after starting snapshopr to my in popular ! we got the last problem we could play a much bigger\n",
      "one epoch complete\n",
      "iteration 4000, loss = 10.1180505753\n",
      "once he was very likely ahead of our time and resources in products and to build and people understand pictures and video content , and may be help robots navigate natural environments . the company we built but based on a personal experience , we ended up choosing e-commerce as our\n",
      "one epoch complete\n",
      "iteration 4500, loss = 7.00016689301\n",
      "to build a world class technology company driven by innovation from me i think i’m going to spend to his family but not that are trying to do but there has still a relatively small percentage people to appreciate the way to join the problem statement . ideally , the system\n",
      "one epoch complete\n",
      "iteration 5000, loss = 4.22842311859\n",
      "machine . we have gone to great lengths to team in the market was all of engineering here . he wanted to buy and our business overall . he believed in me when i told him very best in the form of the success in a startup . we may get\n",
      "one epoch complete\n",
      "one epoch complete\n",
      "iteration 5500, loss = 5.26132440567\n",
      ". we were looking for a long time . he was a hard ai problem which has recently started attracting a lot of interest from , and have helped the team loved artificial intelligence . our goal with research projects to new question , machine learning , reinforcement learning and natural\n",
      "one epoch complete\n",
      "iteration 6000, loss = 1.6957243681\n",
      "the world in technology , india . this was very likely ahead of everyone from his university and other universities such as montreal , toronto and stanford . one of the best possible solution solution in this kind of new technology human which is a few months interesting and hard time\n",
      "one epoch complete\n",
      "iteration 6500, loss = 1.9471912384\n",
      "engineers and scientists , we wanted to structure the company in terms that technology and as a startup . we stand by artifacia research , our unfinished product system create only a lot of new players who are all doing more you . i’ve been a lot of time . we\n",
      "one epoch complete\n",
      "iteration 7000, loss = 1.09219896793\n",
      "power of having a strong vision and natural language processing with other universities of the country , in my small attempt at entrepreneurship i’m determined to build the world we are going to be able to but you think for your competition and copycats in the us with a human .\n",
      "one epoch complete\n",
      "iteration 7500, loss = 1.1055688858\n",
      "building technology products , and we think many he would go about how there are two in separate posts on our research unit research projects couple of creating , based on an industry that’s going hard research search and what causes , you should be part of robotics his robotics teams\n",
      "one epoch complete\n",
      "one epoch complete\n",
      "iteration 8000, loss = 3.87074947357\n",
      "could not find anything similar online using the search . on computer vision and i immediately focus on cracking the best performing startup in the country and one of the best in the field . among companies and google , microsoft and xerox and top universities from the us we were\n",
      "one epoch complete\n",
      "iteration 8500, loss = 2.08141279221\n",
      "the world in such niche fields of research , is has potential to disrupt multiple industries intelligence from technology , systems and an intern . the idea was simple and hard universities came of your innovative edge and become just at 2015 . the thing was certain : he loved robotics\n",
      "one epoch complete\n",
      "iteration 9000, loss = 0.241676300764\n",
      "a lot of responsibilities ranging from bd to finance the indian : team . and we have a great bunch of top institutes is not really commendable . and the other universities that artificial intelligence technology out india . it’s an early stage tech startup only year much a product startups\n",
      "one epoch complete\n",
      "iteration 9500, loss = 2.65148901939\n",
      "experience while interacting with our product experience , has has to take a lot of interest from the question , ‘can machines think ? ’” because the first time and will need to learn more to do a platform play and innovation is closely doing to work that time university ,\n",
      "one epoch complete\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "h = np.zeros(hidden_layer)\n",
    "for i in range(iterations):\n",
    "#     x, y = data.sample(d, num_steps)\n",
    "    if ix + num_steps >= len(d):\n",
    "        ix = 0\n",
    "        print('one epoch complete')\n",
    "    h = np.zeros(hidden_layer)\n",
    "    x, y = d[ix : ix + num_steps], d[ix + 1 : ix + num_steps + 1]   \n",
    "    l, o, _ = sess.run([loss, outputs, optimize_op], {a: x, b: y, initial: h})\n",
    "    if i % 500 == 0:\n",
    "        print('iteration {0}, loss = {1}'.format(i, l))\n",
    "        generate(sess, 50)\n",
    "    ix += num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving model\n",
    "# saver.save(sess, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "much traction which itself required marketing dollars.we were stuck in a vicious loop , to be able to pursue his robotics and robotics passion before that time and that should be part of your product market fit , an industry has , by a month ago , this is an one of the human computer interaction ) . image is very a time . we have a great set to new yourself focused and technology innovation . in the very half of our product or on . and robotics and we could do any path we wanted to and that helped\n"
     ]
    }
   ],
   "source": [
    "generate(sess, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess.run(Whh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
